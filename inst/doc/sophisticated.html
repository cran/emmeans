<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Russ Lenth" />

<meta name="date" content="2018-05-20" />

<title>Sophisticated models in emmeans</title>






<link href="data:text/css;charset=utf-8,body%20%7B%0Afont%2Dsize%3A%2011pt%3B%20font%2Dfamily%3A%20%22Palatino%20Linotype%22%2C%20%22Book%20Antiqua%22%2C%20Palatino%2C%20serif%3B%0Amargin%3A%2030px%2050px%2030px%2050px%3B%20%7D%0Ah1%2Ch2%2Ch3%2Ch4%2Ch5%2Ch6%20%7B%20font%2Dfamily%3A%20Arial%2CHelvetica%2CSans%2Dserif%3B%20%7D%0Aa%20%7B%20text%2Ddecoration%3A%20none%3B%20%7D%0Aa%3Alink%20%7B%20color%3Adarkblue%3B%20%7D%20a%3Avisited%20%7B%20color%3Adarkblue%3B%20%7D%20a%3Ahover%20%7B%20color%3Adodgerblue%3B%20%7D%0Aa%3Aactive%20%7B%20color%3Adodgerblue%3B%20%7D%20code%20%7B%0Acolor%3A%20%23602000%3B%0Afont%2Dfamily%3A%20%22Lucida%20Console%22%2C%20Monaco%2C%20monospace%3B%20font%2Dsize%3A%2090%25%3B%0A%7D%0A%2Er%20%7B%20%0Acolor%3A%20darkred%3B%20%7D%0A%2Ero%20%7B%20%0Acolor%3A%20darkgreen%3B%20background%2Dcolor%3A%20%23eeeeee%3B%20%7D%0A%2Er%20code%2C%20a%20code%2C%20%2Ero%20code%20%7B%20color%3A%20inherit%3B%20%7D%0A%2Evigindex%20ul%20%7B%20list%2Dstyle%2Dtype%3A%20none%3B%20%7D%0A%2Evigindex%20ul%20li%20%7B%20list%2Dstyle%3A%20none%3B%20%7D%0A%2Evigindex%20a%20code%20%7B%20color%3A%20inherit%3B%20%7D%0A%2Evigindex%20li%20code%20%7B%20color%3A%20inherit%3B%20%7D%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">Sophisticated models in emmeans</h1>
<h4 class="author"><em>Russ Lenth</em></h4>
<h4 class="date"><em>2018-05-20</em></h4>



<!-- @index Vignettes!Sophisticated models -->
<p>This vignette gives a few examples of the use of the <strong>emmeans</strong> package to analyze other than the basic types of models provided by the <strong>stats</strong> package. Emphasis here is placed on accessing the optional capabilities that are typically not needed for the more basic models. A reference for all supported models is provided in the <a href="models.html">“models” vignette</a>.</p>
<div id="contents" class="section level2">
<h2>Contents</h2>
<ol style="list-style-type: decimal">
<li><a href="#lmer">Linear mixed models (lmer)</a>
<ol style="list-style-type: lower-alpha">
<li><a href="#lmerOpts">System options for lmerMod models</a></li>
</ol></li>
<li><a href="#offsets">Models with offsets</a></li>
<li><a href="#ordinal">Ordinal models</a></li>
<li><a href="#mcmc">Models fitted using MCMC methods</a></li>
<li><a href="models.html">Reference for supported models</a></li>
</ol>
<p><a href="vignette-topics.html">Index of all vignette topics</a></p>
</div>
<div id="lmer" class="section level2">
<h2>Linear mixed models (lmer)</h2>
<!-- @index `lmerMod` models; Examples!`Oats`; Examples!Split-plot experiment -->
<p>Linear mixed models are really important in statistics. Emphasis here is placed on those fitted using <code>lme4::lmer()</code>, but <strong>emmeans</strong> also supports other mixed-model packages such as <strong>nlme</strong>.</p>
<p>To illustrate, consider the <code>Oats</code> dataset in the <strong>nlme</strong> package. It has the results of a balanced split-plot experiment: experimental blocks are divided into plots that are randomly assigned to oat varieties, and the plots are subdivided into subplots that are randomly assigned to amounts of nitrogen within each plot. We will consider a linear mixed model for these data, excluding interaction (which is justified in this case). For sake of illustration, we will exclude a few observations.</p>
<pre class="r"><code>Oats.lmer &lt;- lme4::lmer(yield ~ Variety + factor(nitro) + (1|Block/Variety),
                        data = nlme::Oats, subset = -c(1,2,3,5,8,13,21,34,55))</code></pre>
<p>Let’s look at the EMMs for <code>nitro</code>:</p>
<pre class="r"><code>Oats.emm.n &lt;- emmeans(Oats.lmer, &quot;nitro&quot;)
Oats.emm.n</code></pre>
<pre class="ro"><code>##  nitro    emmean       SE   df  lower.CL  upper.CL
##    0.0  78.89207 7.294379 7.78  61.98930  95.79484
##    0.2  97.03425 7.136271 7.19  80.25029 113.81822
##    0.4 114.19816 7.136186 7.19  97.41454 130.98179
##    0.6 124.06857 7.070235 6.95 107.32795 140.80919
## 
## Results are averaged over the levels of: Variety 
## Degrees-of-freedom method: kenward-roger 
## Confidence level used: 0.95</code></pre>
<p>You will notice that the degrees of freedom are fractional: that is due to the fact that whole-plot and subplot variations are combined when standard errors are estimated. Different degrees-of-freedom methods are available. By default, the Kenward-Roger method is used, and that’s why you see a message about the <strong>pbkrtest</strong> package being loaded, as it implements that method. We may specify a different degrees-of-freedom method via the optional argument <code>lmer.df</code>:</p>
<pre class="r"><code>emmeans(Oats.lmer, &quot;nitro&quot;, lmer.df = &quot;satterthwaite&quot;)</code></pre>
<pre class="ro"><code>##  nitro    emmean       SE   df  lower.CL  upper.CL
##    0.0  78.89207 7.280608 7.28  61.81122  95.97292
##    0.2  97.03425 7.128706 6.72  80.03161 114.03690
##    0.4 114.19816 7.128885 6.72  97.19535 131.20098
##    0.6 124.06857 7.067304 6.49 107.08857 141.04857
## 
## Results are averaged over the levels of: Variety 
## Degrees-of-freedom method: satterthwaite 
## Confidence level used: 0.95</code></pre>
<div id="dfoptions" class="section level6">
<h6></h6>
<!-- @index Degrees of freedom; *z* tests; Asymptotic tests -->
<p>This latest result uses the Satterthwaite method, which is implemented in the <strong>lmerTest</strong> package. Note that, with this method, not only are the degrees of freedom slightly different, but so are the standard errors. That is because the Kenward-Roger method also entails making a bias adjustment to the covariance matrix of the fixed effects; that is the principal difference between the methods. A third possibility is <code>&quot;asymptotic&quot;</code>:</p>
<pre class="r"><code>emmeans(Oats.lmer, &quot;nitro&quot;, lmer.df = &quot;asymptotic&quot;)</code></pre>
<pre class="ro"><code>##  nitro    emmean       SE  df asymp.LCL asymp.UCL
##    0.0  78.89207 7.280608 Inf  64.62234   93.1618
##    0.2  97.03425 7.128706 Inf  83.06225  111.0063
##    0.4 114.19816 7.128885 Inf 100.22580  128.1705
##    0.6 124.06857 7.067304 Inf 110.21691  137.9202
## 
## Results are averaged over the levels of: Variety 
## Degrees-of-freedom method: asymptotic 
## Confidence level used: 0.95</code></pre>
<p>This just sets all the degrees of freedom to <code>Inf</code> – that’s <strong>emmeans</strong>’s way of using <em>z</em> statistics rather than <em>t</em> statistics. The asymptotic methods tend to make confidence intervals a bit too narrow and P values a bit too low; but they involve much, much less computation. Note that the SEs are the same as obtained using the Satterthwaite method.</p>
<p>Comparisons and contrasts are pretty much the same as with other models. As <code>nitro</code> has quantitative levels, we might want to test polynomial contrasts:</p>
<pre class="r"><code>contrast(Oats.emm.n, &quot;poly&quot;)</code></pre>
<pre class="ro"><code>##  contrast    estimate        SE    df t.ratio p.value
##  linear    152.693407 15.577738 43.23   9.802  &lt;.0001
##  quadratic  -8.271775  6.948552 44.19  -1.190  0.2402
##  cubic      -6.315230 15.205089 42.75  -0.415  0.6800
## 
## Results are averaged over the levels of: Variety</code></pre>
<p>The interesting thing here is that the degrees of freedom are much larger than they are for the EMMs. The reason is because <code>nitro</code> within-plot factor, so inter-plot variations have little role in estimating contrasts among <code>nitro</code> levels. On the other hand, <code>Variety</code> is a whole-plot factor, and there is not much of a bump in degrees of freedom for comparisons:</p>
<pre class="r"><code>emmeans(Oats.lmer, pairwise ~ Variety)</code></pre>
<pre class="ro"><code>## $emmeans
##  Variety        emmean       SE   df lower.CL upper.CL
##  Golden Rain 105.24081 7.531718 8.46 88.03704 122.4446
##  Marvellous  108.46951 7.482632 8.28 91.31571 125.6233
##  Victory      96.93446 7.641645 8.81 79.59011 114.2788
## 
## Results are averaged over the levels of: nitro 
## Degrees-of-freedom method: kenward-roger 
## Confidence level used: 0.95 
## 
## $contrasts
##  contrast                  estimate       SE   df t.ratio p.value
##  Golden Rain - Marvellous -3.228698 6.553848 9.56  -0.493  0.8764
##  Golden Rain - Victory     8.306351 6.707935 9.80   1.238  0.4595
##  Marvellous - Victory     11.535049 6.670488 9.80   1.729  0.2431
## 
## Results are averaged over the levels of: nitro 
## P value adjustment: tukey method for comparing a family of 3 estimates</code></pre>
</div>
<div id="lmerOpts" class="section level3">
<h3>System options for lmerMod models</h3>
<!-- @index `lmerMod` models!System options for -->
<p>The computation required to compute the adjusted covariance matrix and degrees of freedom may become cumbersome. Some user options (i.e., <code>emm_options()</code> calls) make it possible to streamline these computations through default methods and limitations on them. First, the option <code>lmer.df</code>, which may have values of <code>&quot;kenward-roger&quot;</code>, <code>&quot;satterthwaite&quot;</code>, or <code>&quot;asymptotic&quot;</code> (partial matches are OK!) specifies the default degrees-of-freedom method.</p>
<p>The options <code>disable.pbkrtest</code> and <code>disable.lmerTest</code> may be <code>TRUE</code> or <code>FALSE</code>, and comprise another way of controlling which method is used (e.g., the Kenward-Roger method will not be used if <code>get_emm_option(&quot;disable.pbkrtest&quot;) == TRUE</code>). Finally, the options <code>pbkrtest.limit</code> and <code>lmerTest.limit</code>, which should be set to numeric values, enable the given package conditionally on whether the number of data rows does not exceed the given limit. The factory default is 3000 for both limits.</p>
<p><a href="#contents">Back to Contents</a></p>
</div>
</div>
<div id="offsets" class="section level2">
<h2>Models with offsets</h2>
<!-- @index Offsets; Examples!Insurance claims (SAS); `ref_grid()`!`offset` -->
<p>If a model is fitted and its formula includes an <code>offset()</code> term, then by default, the offset is computed and included in the reference grid. To illustrate, consider a hypothetical dataset on insurance claims (used as an <a href="https://support.sas.com/documentation/cdl/en/statug/63033/HTML/default/viewer.htm#statug_genmod_sect006.htm">example in SAS’s documentation</a>). There are classes of cars of varying counts (<code>n</code>), sizes (<code>size</code>), and age (<code>age</code>), and we record the number of insurance claims (<code>claims</code>). We fit a Poisson model to <code>claims</code> as a function of <code>size</code> and <code>age</code>. An offset of <code>log(n)</code> is included so that <code>n</code> functions as an “exposure” variable.</p>
<pre class="r"><code>ins &lt;- data.frame(
    n = c(500, 1200, 100, 400, 500, 300),
    size = factor(rep(1:3,2), labels = c(&quot;S&quot;,&quot;M&quot;,&quot;L&quot;)),
    age = factor(rep(1:2, each = 3)),
    claims = c(42, 37, 1, 101, 73, 14))
ins.glm &lt;- glm(claims ~ size + age + offset(log(n)), 
               data = ins, family = &quot;poisson&quot;)</code></pre>
<p>First, let’s look at the reference grid obtained by default:</p>
<pre class="r"><code>ref_grid(ins.glm)</code></pre>
<pre class="ro"><code>## 'emmGrid' object with variables:
##     size = S, M, L
##     age = 1, 2
##     n = 500
## Transformation: &quot;log&quot;</code></pre>
<p>Note that <code>n</code> is included in the reference grid and that its average value of 500 is used for all predictions. Thus, if we obtain EMMs for, say, <code>age</code>, these are results are based on a pool of 500 cars:</p>
<pre class="r"><code>emmeans(ins.glm, &quot;size&quot;, type = &quot;response&quot;)</code></pre>
<pre class="ro"><code>##  size     rate       SE  df asymp.LCL asymp.UCL
##  S    69.26111 6.250440 Inf 58.032750  82.66198
##  M    34.64335 3.342971 Inf 28.673568  41.85604
##  L    11.86512 3.136904 Inf  7.066934  19.92108
## 
## Results are averaged over the levels of: age 
## Confidence level used: 0.95 
## Intervals are back-transformed from the log scale</code></pre>
<p>However, many users would like to ignore the offset for this kind of model, because then the estimates we obtain are rates per unit value of the (logged) offset. This may be accomplished by specifying an <code>offset</code> parameter in the call:</p>
<pre class="r"><code>emmeans(ins.glm, &quot;size&quot;, type = &quot;response&quot;, offset = 0)</code></pre>
<pre class="ro"><code>##  size       rate          SE  df  asymp.LCL  asymp.UCL
##  S    0.13852223 0.012500880 Inf 0.11606550 0.16532396
##  M    0.06928671 0.006685942 Inf 0.05734714 0.08371208
##  L    0.02373023 0.006273808 Inf 0.01413387 0.03984217
## 
## Results are averaged over the levels of: age 
## Confidence level used: 0.95 
## Intervals are back-transformed from the log scale</code></pre>
<p>You may verify that the above estimates are 1/500th of the previous ones. You may also verify that the above results are identical to those obtained by setting <code>n</code> equal to 1:</p>
<pre class="r"><code>emmeans(ins.glm, &quot;size&quot;, type = &quot;response&quot;, at = list(n = 1))</code></pre>
<p>However, those who use these types of models will be more comfortable directly setting the offset to zero.</p>
<p>By the way, you may set some other reference value for the rates. For example, if you want estimates of claims per 100 cars, simply use (results not shown):</p>
<pre class="r"><code>emmeans(ins.glm, &quot;size&quot;, type = &quot;response&quot;, offset = log(100))</code></pre>
<p><a href="#contents">Back to Contents</a></p>
</div>
<div id="ordinal" class="section level2">
<h2>Ordinal models</h2>
<!-- @index Ordinal models; Examples!`wine`; Examples!Ordinal model
  Ordinal models!Latent scale -->
<p>Ordinal-response models comprise an example where several options are available for obtaining EMMs. To illustrate, consider the <code>wine</code> data in the <strong>ordinal</strong> package. The response is a rating of bitterness on a five-point scale. we will consider a probit model in two factors during fermentation: <code>temp</code> (temperature) and <code>contact</code> (contact with grape skins), with the judge making the rating as a scale predictor:</p>
<pre class="r"><code>require(&quot;ordinal&quot;)</code></pre>
<pre><code>## Loading required package: ordinal</code></pre>
<pre class="r"><code>wine.clm &lt;- clm(rating ~ temp + contact, scale = ~ judge,
                data = wine, link = &quot;probit&quot;)</code></pre>
<p>(in earlier modeling, we found little interaction between the factors.) Here are the EMMs for each factor using default options:</p>
<pre class="r"><code>emmeans(wine.clm, list(pairwise ~ temp, pairwise ~ contact))</code></pre>
<pre class="ro"><code>## $`emmeans of temp`
##  temp     emmean        SE  df  asymp.LCL  asymp.UCL
##  cold -0.8838870 0.2898157 Inf -1.4519155 -0.3158586
##  warm  0.6011128 0.2246028 Inf  0.1608993  1.0413263
## 
## Results are averaged over the levels of: contact, judge 
## Confidence level used: 0.95 
## 
## $`pairwise differences of temp`
##  contrast     estimate        SE  df z.ratio p.value
##  cold - warm -1.073545 0.4215306 Inf  -2.547  0.0109
## 
## Results are averaged over the levels of: contact, judge 
## 
## $`emmeans of contact`
##  contact     emmean        SE  df   asymp.LCL   asymp.UCL
##  no      -0.6143569 0.2983133 Inf -1.19904027 -0.02967357
##  yes      0.3315827 0.2014363 Inf -0.06322522  0.72639062
## 
## Results are averaged over the levels of: temp, judge 
## Confidence level used: 0.95 
## 
## $`pairwise differences of contact`
##  contrast   estimate        SE  df z.ratio p.value
##  no - yes -0.6838446 0.3038508 Inf  -2.251  0.0244
## 
## Results are averaged over the levels of: temp, judge</code></pre>
<p>These results are on the “latent” scale; the idea is that there is a continuous random variable (in this case normal, due to the probit link) having a mean that depends on the predictors; and that the ratings are a discretization of the latent variable based on a fixed set of cut points (which are estimated). In this particular example, we also have a scale model that says that the variance of the latent variable depends on the judges. The latent results are quite a bit like those for measurement data, making them easy to interpret. The only catch is that they are not uniquely defined: we could apply a linear transformation to them, and the same linear transformation to the cut points, and the results would be the same.</p>
<div id="ordlp" class="section level6">
<h6></h6>
<!-- @index Ordinal models!Linear-predictor scale -->
<p>The <code>clm</code> function actually fits the model using an ordinary probit model but with different intercepts for each cut point. We can get detailed information for this model by specifying <code>mode = &quot;linear.predictor&quot;</code>:</p>
<pre class="r"><code>tmp &lt;- ref_grid(wine.clm, mode = &quot;lin&quot;)
tmp</code></pre>
<pre class="ro"><code>## 'emmGrid' object with variables:
##     temp = cold, warm
##     contact = no, yes
##     judge = 1, 2, 3, 4, 5, 6, 7, 8, 9
##     cut = multivariate response levels: 1|2, 2|3, 3|4, 4|5
## Transformation: &quot;probit&quot;</code></pre>
<p>Note that this reference grid involves an additional constructed predictor named <code>cut</code> that accounts for the different intercepts in the model. Let’s obtain EMMs for <code>temp</code> on the linear-predictor scale:</p>
<pre class="r"><code>emmeans(tmp, &quot;temp&quot;)</code></pre>
<pre class="ro"><code>##  temp     emmean        SE  df  asymp.LCL  asymp.UCL
##  cold  0.8838870 0.2898157 Inf  0.3158586  1.4519155
##  warm -0.6011128 0.2246028 Inf -1.0413263 -0.1608993
## 
## Results are averaged over the levels of: contact, judge, cut 
## Results are given on the probit (not the response) scale. 
## Confidence level used: 0.95</code></pre>
<p>These are just the negatives of the latent results obtained earlier (the sign is changed to make the comparisons go the right direction). Closely related to this is <code>mode = &quot;cum.prob&quot;</code> and <code>mode = &quot;exc.prob&quot;</code>, which simply transform the linear predictor to cumulative probabilities and exceedance (1 - cumulative) probabilities. These modes give us access to the details of the fitted model but are cumbersome to use for describing results. When they can become useful is when you want to work in terms of a particular cut point. Let’s look at <code>temp</code> again in terms of the probability that the rating will be at least 4:</p>
<pre class="r"><code>emmeans(wine.clm, ~ temp, mode = &quot;exc.prob&quot;, at = list(cut = &quot;3|4&quot;))</code></pre>
<pre class="ro"><code>##  temp   exc.prob         SE  df  asymp.LCL asymp.UCL
##  cold 0.07477754 0.03183196 Inf 0.01238804 0.1371670
##  warm 0.40688371 0.07056873 Inf 0.26857154 0.5451959
## 
## Results are averaged over the levels of: contact, judge 
## Confidence level used: 0.95</code></pre>
</div>
<div id="ordprob" class="section level6">
<h6></h6>
<!-- @index Ordinal models!`prob` and `mean.class` -->
<p>There are yet more modes! With <code>mode = &quot;prob&quot;</code>, we obtain estimates of the probability distribution of each rating. Its reference grid includes a factor with the same name as the model response – in this case <code>rating</code>. We usually want to use that as the primary factor, and the factors of interest as <code>by</code> variables:</p>
<pre class="r"><code>emmeans(wine.clm, ~ rating | temp, mode = &quot;prob&quot;)</code></pre>
<pre class="ro"><code>## temp = cold:
##  rating       prob         SE  df    asymp.LCL  asymp.UCL
##  1      0.12922075 0.06252864 Inf  0.006666872 0.25177462
##  2      0.48768408 0.07051118 Inf  0.349484709 0.62588345
##  3      0.30831763 0.05942035 Inf  0.191855896 0.42477937
##  4      0.05766120 0.02378461 Inf  0.011044211 0.10427818
##  5      0.01711634 0.01265193 Inf -0.007680992 0.04191368
## 
## temp = warm:
##  rating       prob         SE  df    asymp.LCL  asymp.UCL
##  1      0.01561393 0.01287141 Inf -0.009613574 0.04084144
##  2      0.14730458 0.04475283 Inf  0.059590654 0.23501851
##  3      0.43019777 0.06274049 Inf  0.307228674 0.55316687
##  4      0.26845558 0.06251632 Inf  0.145925842 0.39098532
##  5      0.13842813 0.05061119 Inf  0.039232030 0.23762424
## 
## Results are averaged over the levels of: contact, judge 
## Confidence level used: 0.95</code></pre>
<p>Using <code>mode = &quot;mean.class&quot;</code> obtains the average of these probability distributions as probabilities of the integers 1–5:</p>
<pre class="r"><code>emmeans(wine.clm, &quot;temp&quot;, mode = &quot;mean.class&quot;)</code></pre>
<pre class="ro"><code>##  temp mean.class        SE  df asymp.LCL asymp.UCL
##  cold   2.345768 0.1438341 Inf  2.063859  2.627678
##  warm   3.366779 0.1462579 Inf  3.080119  3.653440
## 
## Results are averaged over the levels of: contact, judge 
## Confidence level used: 0.95</code></pre>
<p>And there is a mode for the scale model too. In this example, the scale model involves only judges, and that is the only factor in the grid:</p>
<pre class="r"><code>summary(ref_grid(wine.clm, mode = &quot;scale&quot;), type = &quot;response&quot;)</code></pre>
<pre class="ro"><code>##  judge  response        SE  df
##  1     1.0000000 0.0000000 Inf
##  2     1.0429804 0.5696650 Inf
##  3     1.0526798 0.4811605 Inf
##  4     0.7103256 0.3356562 Inf
##  5     0.6632397 0.3009780 Inf
##  6     0.7582403 0.3411929 Inf
##  7     1.0707070 0.5861427 Inf
##  8     0.2409019 0.1791135 Inf
##  9     0.5331235 0.3110024 Inf</code></pre>
<p>Judge 8’s ratings don’t vary much, relative to the others. The scale model is in terms of log(SD). Again, these are not uniquely identifiable, and the first level’s estimate is set to log(1) = 0. so, actually, each estimate shown is a comparison with judge 1.</p>
<p><a href="#contents">Back to Contents</a></p>
</div>
</div>
<div id="mcmc" class="section level2">
<h2>Models fitted using MCMC methods</h2>
<!-- @index Bayesian models; Examples!Bayesian model; Examples!`cbpp`
    `rstanarm`; `hpd.summary()`; `summary()`!HPD intervals -->
<p>To illustrate <strong>emmeans</strong>’s support for models fitted using MCMC methods, consider the <code>example_model</code> available in the <strong>rstanarm</strong> package. The example concerns CBPP, a serious disease of cattle in Ethiopia. A generalized linear mixed model was fitted to the data using the code below. We subsequently obtain its reference grid in the usual way. <!--- I'm faking this; I actually saved the ref_grid in a system file ---></p>
<pre class="r"><code>example_model &lt;- rstanarm::stan_glmer(
    cbind(incidence, size - incidence) ~ size + period + (1|herd),
    data = lme4::cbpp, family = binomial,
    chains = 2, cores = 1, seed = 12345, iter = 500)
cbpp.rg &lt;- ref_grid(example_model)</code></pre>
<!--- here's the system file with the ref_grid --->
<p>Here is the structure of the reference grid:</p>
<pre class="r"><code>cbpp.rg</code></pre>
<pre class="ro"><code>## 'emmGrid' object with variables:
##     size = 15.036
##     period = 1, 2, 3, 4
## Transformation: &quot;logit&quot;</code></pre>
<p>And, again in the usual way, we can obtain EMMs:</p>
<pre class="r"><code>period.emm &lt;- emmeans(cbpp.rg, &quot;period&quot;)
period.emm</code></pre>
<pre class="ro"><code>##  period    emmean lower.HPD  upper.HPD
##  1      -1.430450 -1.959630 -0.8940016
##  2      -2.394991 -3.132075 -1.8225853
##  3      -2.515846 -3.190710 -1.8616529
##  4      -2.967635 -3.884121 -1.9977081
## 
## Results are given on the logit (not the response) scale. 
## HPD interval probability: 0.95</code></pre>
<p>The summary for EMMs of Bayesian models shows the median of the posterior distribution of each estimate, along with highest posterior density (HPD) intervals. Under the hood, the posterior sample of parameter estimates is used to compute a corresponding sample of posterior EMMs, and it is those that are summarized. (Technical note: the summary is actually rerouted to the <code>hpd.summary()</code> function, and it loads the <strong>coda</strong> package if it is not already loaded.</p>
<div id="bayesxtra" class="section level6">
<h6></h6>
<!-- @index `as.mcmc()`; **coda** package; **bayesplot** package; -->
<p>We can access the posterior EMMs via the <code>as.mcmc</code> method for <code>emmGrid</code> objects. This gives us an object of class <code>mcmc</code> (defined in the <strong>coda</strong> package), which can be summarized and explored as we please.</p>
<pre class="r"><code>require(&quot;coda&quot;)</code></pre>
<pre><code>## Loading required package: coda</code></pre>
<pre class="r"><code>summary(as.mcmc(period.emm))</code></pre>
<pre class="ro"><code>## 
## Iterations = 1:250
## Thinning interval = 1 
## Number of chains = 2 
## Sample size per chain = 250 
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##            Mean     SD Naive SE Time-series SE
## period 1 -1.435 0.2825  0.01264        0.01771
## period 2 -2.393 0.3374  0.01509        0.01620
## period 3 -2.516 0.3409  0.01524        0.01540
## period 4 -2.979 0.4634  0.02072        0.02793
## 
## 2. Quantiles for each variable:
## 
##            2.5%    25%    50%    75%  97.5%
## period 1 -1.969 -1.618 -1.430 -1.262 -0.903
## period 2 -3.122 -2.609 -2.395 -2.165 -1.746
## period 3 -3.199 -2.739 -2.516 -2.286 -1.870
## period 4 -3.890 -3.254 -2.968 -2.698 -2.003</code></pre>
<p>Note that <code>as.mcmc</code> will actually produce an <code>mcmc.list</code> when there is more than one chain present, as in this example. The 2.5th and 97.5th quantiles are similar, but not identical, to the 95% confidence intervals in the frequentist summary. Here is a plot of the posterior EMMs, back-transformed:</p>
<pre class="r"><code>bayesplot::mcmc_areas(as.mcmc(regrid(period.emm)))</code></pre>
<p><img src="data:image/png;base64,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" width="432" /></p>
<p>… and here are intervals for each period compared with its neighbor:</p>
<pre class="r"><code>contrast(period.emm, &quot;consec&quot;, reverse = TRUE)</code></pre>
<pre class="ro"><code>##  contrast  estimate  lower.HPD upper.HPD
##  1 - 2    0.9544005  0.3749803 1.5329574
##  2 - 3    0.1332683 -0.5813314 0.9415829
##  3 - 4    0.4394573 -0.4765553 1.6714750
## 
## Results are given on the log odds ratio (not the response) scale. 
## HPD interval probability: 0.95</code></pre>
<p>The only interval that excludes zero is the one that compares periods 1 and 2.</p>
<p>In summary, to do Bayesian analysis in the <strong>emmeans</strong> package, use the same tools that are available for other models, extract the MCMC samples using <code>as.mcmc()</code>, and summarize or plot from there.</p>
<p><a href="#contents">Back to Contents</a></p>
<p><a href="vignette-topics.html">Index of all vignette topics</a></p>
</div>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
